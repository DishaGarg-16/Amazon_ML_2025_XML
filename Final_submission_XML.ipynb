{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7vnE-7AzOoq",
        "outputId": "c86821d8-2d72-4acb-f646-6df9bccb6eac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas numpy torch torchvision transformers scikit-learn tqdm requests"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler, QuantileTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "from functools import partial"
      ],
      "metadata": {
        "id": "7aZIl7Z7zVS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7o82pqsIdKk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NS3_OXOadYZ-",
        "outputId": "c0549250-96c4-4430-eb0e-9f6482a08a83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "# --- CONFIGURATION (UPDATE PATHS AS NEEDED) ---\n",
        "TRAIN_FILE = '/content/drive/MyDrive/student_resource/dataset/train.csv'\n",
        "TEST_FILE = '/content/drive/MyDrive/student_resource/dataset/test.csv'\n",
        "TOP_N_BRANDS = 100\n",
        "\n",
        "# --- CRUCIAL ADDITION: Define Feature List Variables ---\n",
        "NUM_FEATURES = ['unit_vol', 'pack_count', 'total_qty']\n",
        "CAT_FEATURES = ['brand', 'unit_measure']\n",
        "# Define the function that will NOT drop rows\n",
        "def extract_structured_features_ROBUST(df):\n",
        "    \"\"\"\n",
        "    Extracts Brand, IPQ components, and transforms the target,\n",
        "    using 'errors=coerce' to ensure all 75,000 rows are retained.\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. IPQ/Unit Extraction (Robust to errors)\n",
        "\n",
        "    # Extract unit volume string\n",
        "    unit_vol_extracted = df['catalog_content'].str.extract(r'(\\d*\\.?\\d+)\\s+(Ounce|oz|Lb|lb|Pound|ct|Count|Liter|LT|Fl Oz)', re.IGNORECASE)[0]\n",
        "    # Convert to numeric, forcing errors to NaN\n",
        "    df['unit_vol'] = pd.to_numeric(unit_vol_extracted, errors='coerce')\n",
        "\n",
        "    # Extract unit measure\n",
        "    df['unit_measure'] = df['catalog_content'].str.extract(r'(\\d*\\.?\\d+)\\s+(Ounce|oz|Lb|lb|Pound|ct|Count|Liter|LT|Fl Oz)', re.IGNORECASE)[1].fillna('NONE').str.lower()\n",
        "\n",
        "    # Extract pack count string\n",
        "    pack_count_extracted = df['catalog_content'].str.extract(r'(Pack of|PK-| case| count)\\s*(\\d+)', re.IGNORECASE)[1].fillna('1')\n",
        "\n",
        "    # Convert to numeric, forcing errors to NaN, then fill NaNs with 1, and convert to int\n",
        "    df['pack_count'] = pd.to_numeric(pack_count_extracted, errors='coerce').fillna(1).astype(int)\n",
        "\n",
        "    # 2. Total Quantity Feature\n",
        "    # Fill unit_vol NaNs with 1.0 here so multiplication works without dropping rows\n",
        "    df['total_qty'] = df['unit_vol'].fillna(1.0) * df['pack_count']\n",
        "\n",
        "    # 3. Brand Extraction (Keeps the original logic for consistency)\n",
        "    def extract_brand(text):\n",
        "        try:\n",
        "            name_part = text.split(',')[0].split('Item Name: ')[-1]\n",
        "            return ' '.join(name_part.split(' ')[:3])\n",
        "        except:\n",
        "            return 'UNKNOWN'\n",
        "\n",
        "    df['brand'] = df['catalog_content'].apply(extract_brand)\n",
        "\n",
        "    # 4. Target Transformation\n",
        "    if 'price' in df.columns:\n",
        "        df['log_price'] = np.log1p(df['price'])\n",
        "\n",
        "    # Crucial: DO NOT drop the catalog_content/image_link columns yet if you need them later\n",
        "    # We will let the subsequent preprocessing step handle column drops.\n",
        "    return df\n",
        "\n",
        "\n",
        "# --- Execution Flow with Verification ---\n",
        "\n",
        "TRAIN_FILE = '/content/drive/MyDrive/student_resource/dataset/train.csv'\n",
        "TEST_FILE = '/content/drive/MyDrive/student_resource/dataset/test.csv'\n",
        "\n",
        "df_train = pd.read_csv(TRAIN_FILE)\n",
        "df_test = pd.read_csv(TEST_FILE)\n",
        "\n",
        "# Retain original raw text before processing\n",
        "df_train_raw = df_train.copy()\n",
        "df_test_raw = df_test.copy()\n",
        "\n",
        "# Apply the fixed function\n",
        "df_train = extract_structured_features_ROBUST(df_train)\n",
        "df_test = extract_structured_features_ROBUST(df_test)\n",
        "\n",
        "# --- CRITICAL VERIFICATION CHECK ---\n",
        "if len(df_test) != 75000:\n",
        "    print(f\"\\nFATAL ERROR: Row count mismatch after fixed extraction. Count is {len(df_test)}\")\n",
        "else:\n",
        "    print(\"Stage 1 Complete. All 75,000 TEST rows retained. Proceed to Stage 2.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gPlHrzxMlLi",
        "outputId": "3f6c8860-4028-4afe-ade9-fdeab5ebd3e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stage 1 Complete. All 75,000 TEST rows retained. Proceed to Stage 2.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1.1 & 1.2: Load Data and Extract Features ---\n",
        "# Apply the 'engine=' and 'on_bad_lines=' parameters to handle parsing errors\n",
        "\n",
        "df_train = pd.read_csv(\n",
        "    TRAIN_FILE,\n",
        "    engine='python',            # Use the more flexible Python parser\n",
        "    on_bad_lines='warn'         # Warn about bad lines but try to process them\n",
        ")\n",
        "df_test = pd.read_csv(\n",
        "    TEST_FILE,\n",
        "    engine='python',\n",
        "    on_bad_lines='warn'\n",
        ")\n",
        "\n",
        "# Keep raw text for TF-IDF in Stage 3\n",
        "df_train_raw = df_train.copy()\n",
        "df_test_raw = df_test.copy()\n",
        "\n",
        "df_train = extract_structured_features_ROBUST(df_train)\n",
        "df_test = extract_structured_features_ROBUST(df_test)\n",
        "\n",
        "print(\"Stage 1 Complete. Data loaded successfully with Python engine.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5erHfS5_LNn",
        "outputId": "6f11b3aa-677b-4004-f7d2-33ab8bdc830c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stage 1 Complete. Data loaded successfully with Python engine.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Configuration (Fit ONLY on Training Data) ---\n",
        "\n",
        "# 1. Fit numerical scaler on training data\n",
        "scaler = StandardScaler()\n",
        "# Fill NaNs with the median before fitting/transforming\n",
        "df_train[NUM_FEATURES] = df_train[NUM_FEATURES].fillna(df_train[NUM_FEATURES].median())\n",
        "scaler.fit(df_train[NUM_FEATURES])\n",
        "\n",
        "# 2. Identify top brands from training data\n",
        "brand_counts = df_train['brand'].value_counts()\n",
        "top_brands = brand_counts[brand_counts > TOP_N_BRANDS].index.tolist()\n",
        "\n",
        "def preprocess_structured_features(df, scaler, top_brands):\n",
        "    df_proc = df.copy()\n",
        "\n",
        "    # Handle NaNs in numerical features (using the same value as the fit step)\n",
        "    df_proc[NUM_FEATURES] = df_proc[NUM_FEATURES].fillna(df_train[NUM_FEATURES].median().to_dict())\n",
        "\n",
        "    # 2.2: Apply numerical scaling\n",
        "    df_proc[NUM_FEATURES] = scaler.transform(df_proc[NUM_FEATURES])\n",
        "\n",
        "    # Categorical Encoding: Reduce high-cardinality brand feature\n",
        "    df_proc['brand_encoded'] = df_proc['brand'].apply(lambda x: x if x in top_brands else 'OTHER')\n",
        "\n",
        "    # One-Hot Encoding for the reduced set of categories\n",
        "    ohe_features = ['brand_encoded', 'unit_measure']\n",
        "    dummies = pd.get_dummies(df_proc[ohe_features], prefix=['brand', 'unit'])\n",
        "\n",
        "    # Drop original categorical and un-needed columns\n",
        "    df_proc = pd.concat([df_proc, dummies], axis=1).drop(columns=CAT_FEATURES + ohe_features + ['catalog_content', 'image_link'])\n",
        "\n",
        "    return df_proc\n",
        "\n",
        "# --- 2.2: Apply Preprocessing ---\n",
        "df_train_proc = preprocess_structured_features(df_train.copy(), scaler, top_brands)\n",
        "df_test_proc = preprocess_structured_features(df_test.copy(), scaler, top_brands)\n",
        "\n",
        "# --- 2.3: CRITICAL: Align columns for Test Set ---\n",
        "train_cols = [c for c in df_train_proc.columns if c not in ['sample_id', 'price', 'log_price']]\n",
        "\n",
        "for col in train_cols:\n",
        "    if col not in df_test_proc.columns:\n",
        "        df_test_proc[col] = 0\n",
        "\n",
        "df_test_proc = df_test_proc[['sample_id'] + train_cols] # Ensure column order matches\n",
        "df_train_proc = df_train_proc[['sample_id', 'log_price'] + train_cols]\n",
        "\n",
        "print(\"Stage 2 Complete. Structured features scaled and encoded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sRTZauE_M1M",
        "outputId": "319e4d87-a897-4f31-b06b-64f3767574f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stage 2 Complete. Structured features scaled and encoded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3.1 & 3.2: TF-IDF Vectorization ---\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import os\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack, csr_matrix # <-- ADD THIS LINE\n",
        "import lightgbm as lgb\n",
        "train_text = df_train_raw['catalog_content'].fillna('')\n",
        "test_text = df_test_raw['catalog_content'].fillna('')\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=10000,\n",
        "    ngram_range=(1, 2),\n",
        "    stop_words='english',\n",
        "    analyzer='word'\n",
        ")\n",
        "\n",
        "# Fit and Transform on TRAINING data\n",
        "X_train_text = vectorizer.fit_transform(train_text)\n",
        "# Transform ONLY on TEST data\n",
        "X_test_text = vectorizer.transform(test_text)\n",
        "\n",
        "# --- 3.3: Combine Text and Structured Features ---\n",
        "\n",
        "# Select feature columns from processed DFs\n",
        "FEATURE_COLS = [col for col in df_train_proc.columns if col not in ['sample_id', 'price', 'log_price']]\n",
        "\n",
        "X_train_struct_df = df_train_proc[FEATURE_COLS]\n",
        "X_test_struct_df = df_test_proc[FEATURE_COLS]\n",
        "\n",
        "# CRITICAL FIX: Explicitly cast to float64 for sparse matrix compatibility\n",
        "X_train_struct = X_train_struct_df.astype(np.float64).values\n",
        "X_test_struct = X_test_struct_df.astype(np.float64).values\n",
        "\n",
        "# Combine sparse text matrix with dense structured matrix\n",
        "X_train_final = hstack([X_train_text, csr_matrix(X_train_struct)])\n",
        "X_test_final = hstack([X_test_text, csr_matrix(X_test_struct)])\n",
        "\n",
        "y_train = df_train_proc['log_price']\n",
        "\n",
        "print(\"Stage 3 Complete. Feature matrices stacked.\")\n",
        "print(f\"Final Combined Feature Shape (Train): {X_train_final.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjjezpeJALP6",
        "outputId": "915c3003-1cb5-4f7e-faf3-474769d40e69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stage 3 Complete. Feature matrices stacked.\n",
            "Final Combined Feature Shape (Train): (75000, 10021)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4.1: Train LightGBM Model ---\n",
        "\n",
        "# LightGBM is trained on log-price\n",
        "lgb_model = lgb.LGBMRegressor(\n",
        "    objective='regression',\n",
        "    metric='mse',\n",
        "    n_estimators=1500,\n",
        "    learning_rate=0.03,\n",
        "    num_leaves=63,\n",
        "    max_depth=-1,\n",
        "    n_jobs=-1,\n",
        "    random_state=42,\n",
        "    verbose=-1\n",
        ")\n",
        "\n",
        "print(\"\\nStarting LightGBM Training...\")\n",
        "lgb_model.fit(X_train_final, y_train)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# --- 4.2 & 4.3: Prediction and Inverse Transformation ---\n",
        "\n",
        "# Generate predictions on the test set (in log scale)\n",
        "y_pred_log = lgb_model.predict(X_test_final)\n",
        "\n",
        "# Inverse transform: price = exp(log_price) - 1\n",
        "y_pred_price = np.expm1(y_pred_log)\n",
        "\n",
        "# Constraint: Clamp to minimum of 0.01 to ensure strictly positive values\n",
        "y_pred_price = np.maximum(0.01, y_pred_price)\n",
        "\n",
        "# --- 4.4: Format Submission File ---\n",
        "\n",
        "sample_ids = df_test_raw['sample_id']\n",
        "\n",
        "output_df = pd.DataFrame({\n",
        "    'sample_id': sample_ids,\n",
        "    'price': y_pred_price\n",
        "})\n",
        "\n",
        "# Save to CSV (Constraint: Match sample output format exactly - float_format='%.2f')\n",
        "OUTPUT_FILE = 'submission_baseline_lgbm_tfidf.csv'\n",
        "output_df.to_csv(OUTPUT_FILE, index=False, float_format='%.2f')\n",
        "\n",
        "print(f\"\\n✅ Submission file created: {OUTPUT_FILE}\")\n",
        "print(\"Your Text-Only LightGBM baseline is complete and ready for evaluation!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GLmkMgaAON_",
        "outputId": "31d8fcb3-b641-405e-aaf1-b5d5f14bf8a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting LightGBM Training...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "# Assuming drive.mount('/content/drive') was run successfully.\n",
        "\n",
        "# --- 1. Define the Project Root and File Paths (Using your structure) ---\n",
        "PROJECT_NAME = 'student_resource'\n",
        "BASE_DIR = os.path.join('/content/drive/MyDrive', PROJECT_NAME)\n",
        "\n",
        "# Ensure pandas is imported before use\n",
        "# No need to redefine df_train/test here, just the paths\n",
        "TRAIN_FILE = os.path.join(BASE_DIR, 'dataset', 'train.csv')\n",
        "TEST_FILE = os.path.join(BASE_DIR, 'dataset', 'test.csv')\n",
        "IMAGE_DOWNLOAD_FOLDER = os.path.join(BASE_DIR, 'dataset', 'product_images')\n",
        "\n",
        "# --- 2. CRITICAL FIX: Connect utils.py to Python's Path and Import ---\n",
        "\n",
        "# 2a. Add 'src' directory to system path\n",
        "SRC_DIR = os.path.join(BASE_DIR, 'src')\n",
        "if SRC_DIR not in sys.path:\n",
        "    sys.path.append(SRC_DIR)\n",
        "\n",
        "# 2b. Import the utility function after updating sys.path\n",
        "try:\n",
        "    # This is the line that defines download_images, fixing the NameError\n",
        "    from utils import download_images\n",
        "    print(\"✅ utils.py imported successfully. Proceeding with loading.\")\n",
        "except ImportError as e:\n",
        "    # This prints if utils.py is missing or has an error inside\n",
        "    print(f\"FATAL ERROR: Could not import utils. Check that utils.py is in the {SRC_DIR} folder and has no errors inside.\")\n",
        "    raise # Stop execution as subsequent steps will fail\n",
        "\n",
        "# --- 3. Robust Data Loading ---\n",
        "df_train = pd.read_csv(TRAIN_FILE, engine='python', on_bad_lines='warn')\n",
        "df_test = pd.read_csv(TEST_FILE, engine='python', on_bad_lines='warn')\n",
        "\n",
        "# Keep raw dataframes for links and TF-IDF text\n",
        "df_train_raw = df_train.copy()\n",
        "df_test_raw = df_test.copy()\n",
        "\n",
        "print(\"Initial data loading complete.\")\n",
        "# --- Configuration (Based on your confirmed drive structure) ---\n",
        "PROJECT_NAME = 'student_resource'\n",
        "BASE_DIR = os.path.join('/content/drive/MyDrive', PROJECT_NAME)\n",
        "DATASET_FOLDER = os.path.join(BASE_DIR, 'dataset')\n",
        "IMAGE_DOWNLOAD_FOLDER = os.path.join(DATASET_FOLDER, 'product_images')\n",
        "\n",
        "TRAIN_FILE = os.path.join(DATASET_FOLDER, 'train.csv')\n",
        "TEST_FILE = os.path.join(DATASET_FOLDER, 'test.csv')\n",
        "\n",
        "# Load RAW data (required to get all image links)\n",
        "df_train_raw = pd.read_csv(TRAIN_FILE, engine='python', on_bad_lines='warn')\n",
        "df_test_raw = pd.read_csv(TEST_FILE, engine='python', on_bad_lines='warn')\n",
        "\n",
        "\n",
        "# --- 1. Cleanup and Deletion of Corrupt Files (Space Recovery) ---\n",
        "def clean_and_verify_files(image_dir):\n",
        "    \"\"\"Deletes zero-byte files, which often result in duplicated file system space usage.\"\"\"\n",
        "    if not os.path.exists(image_dir):\n",
        "        os.makedirs(image_dir, exist_ok=True)\n",
        "        return 0\n",
        "\n",
        "    # Ensure Colab filesystem cache is refreshed\n",
        "    !ls -R \"{image_dir}\" > /dev/null\n",
        "\n",
        "    file_list = os.listdir(image_dir)\n",
        "    zero_byte_count = 0\n",
        "\n",
        "    for filename in file_list:\n",
        "        file_path = os.path.join(image_dir, filename)\n",
        "        try:\n",
        "            # Check file size (os.path.getsize)\n",
        "            if os.path.getsize(file_path) == 0:\n",
        "                os.remove(file_path)\n",
        "                zero_byte_count += 1\n",
        "\n",
        "        except FileNotFoundError:\n",
        "            continue\n",
        "        except Exception:\n",
        "            continue\n",
        "\n",
        "    print(f\"Cleanup finished. Deleted {zero_byte_count} zero-byte files.\")\n",
        "    return len(os.listdir(image_dir))\n",
        "\n",
        "# Execute Cleanup\n",
        "clean_and_verify_files(IMAGE_DOWNLOAD_FOLDER)\n",
        "\n",
        "\n",
        "# --- 2. Optimized Download (Get ONLY the Missing Images) ---\n",
        "def ensure_missing_images_downloaded():\n",
        "\n",
        "    # 2.1 Get the list of all required links\n",
        "    train_links = df_train_raw['image_link'].dropna().tolist()\n",
        "    test_links = df_test_raw['image_link'].dropna().tolist()\n",
        "    all_links = list(set(train_links + test_links))\n",
        "\n",
        "    # 2.2 Filter links to only include those whose filenames are NOT present\n",
        "    # os.listdir() is used to check existing file names\n",
        "    existing_filenames = set(os.listdir(IMAGE_DOWNLOAD_FOLDER))\n",
        "    links_to_download = []\n",
        "\n",
        "    for link in all_links:\n",
        "        filename = Path(link).name\n",
        "        # If the filename does not exist in the folder, we need to download it\n",
        "        if filename not in existing_filenames:\n",
        "            links_to_download.append(link)\n",
        "\n",
        "    if not links_to_download:\n",
        "        print(f\"✅ All {len(all_links)} required images are present and clean. Proceeding...\")\n",
        "        return\n",
        "\n",
        "    print(f\"Total required unique images: {len(all_links)}\")\n",
        "    print(f\"⚡ Starting download for {len(links_to_download)} missing images...\")\n",
        "\n",
        "    # 2.3 Call the download function with the filtered list\n",
        "    download_images(links_to_download, IMAGE_DOWNLOAD_FOLDER)\n",
        "\n",
        "    print(\"Image download process finished.\")\n",
        "    print(f\"Total files in folder: {len(os.listdir(IMAGE_DOWNLOAD_FOLDER))}\")\n",
        "\n",
        "# Execute the final download step:\n",
        "ensure_missing_images_downloaded()"
      ],
      "metadata": {
        "id": "VGrtGK6OTIWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. Image Preprocessing Pipeline ---\n",
        "IMAGE_TRANSFORM = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    \"\"\"Loads and transforms a single image with fallback.\"\"\"\n",
        "    try:\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        return IMAGE_TRANSFORM(image)\n",
        "    except Exception:\n",
        "        # Fallback: Return a tensor of zeros for missing/corrupt images\n",
        "        return torch.zeros(3, 224, 224)\n",
        "\n",
        "# --- 2. CNN Feature Extraction ---\n",
        "def extract_cnn_features(df_raw, image_dir, batch_size=64, model_name='resnet18'):\n",
        "\n",
        "    # Use ResNet-18 (fast) or VGG-16/19\n",
        "    model = getattr(models, model_name)(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
        "\n",
        "    # Remove the final classification layer (for feature extraction)\n",
        "    model.fc = nn.Identity()\n",
        "    model.eval()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device) # CRITICAL: Move model to GPU\n",
        "\n",
        "    # Prepare list of preprocessed image tensors\n",
        "    image_tensors = [preprocess_image(os.path.join(image_dir, Path(link).name))\n",
        "                     for link in df_raw['image_link']]\n",
        "\n",
        "    features = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in tqdm(range(0, len(image_tensors), batch_size), desc=\"Extracting Image Features\"):\n",
        "            batch = image_tensors[i:i + batch_size]\n",
        "            batch = torch.stack(batch).to(device) # CRITICAL: Move data to GPU\n",
        "\n",
        "            output = model(batch)\n",
        "            features.append(output.cpu().numpy())\n",
        "\n",
        "    return np.vstack(features)\n",
        "\n",
        "# --- Execution ---\n",
        "IMAGE_DIR = 'dataset/product_images'\n",
        "\n",
        "X_train_img_features = extract_cnn_features(df_train_raw, IMAGE_DIR)\n",
        "X_test_img_features = extract_cnn_features(df_test_raw, IMAGE_DIR)\n",
        "\n",
        "print(\"Phase 1 Complete. Image features extracted using Transfer Learning.\")"
      ],
      "metadata": {
        "id": "Qh6-N-9lTJDf",
        "outputId": "164d8057-9db1-4184-f851-d057b22aaa4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 72.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Model 2: Image-Only Price Prediction ---\n",
        "\n",
        "# Assume y_train (log_price) is available from your Stage 1/2 processing\n",
        "y_train = df_train_proc['log_price']\n",
        "\n",
        "lgb_image_model = lgb.LGBMRegressor(\n",
        "    objective='regression', n_estimators=1000, learning_rate=0.05, n_jobs=-1, random_state=42, verbose=-1\n",
        ")\n",
        "\n",
        "print(\"\\nStarting Image-Only LightGBM Training...\")\n",
        "lgb_image_model.fit(X_train_img_features, y_train)\n",
        "\n",
        "# Generate log-price predictions\n",
        "preds_train_img_log = lgb_image_model.predict(X_train_img_features)\n",
        "preds_test_img_log = lgb_image_model.predict(X_test_img_features)\n",
        "\n",
        "# --- 4. Ensemble (Blending) ---\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "# NOTE: Rerun your first LGBM model (Text+Struct) to get these predictions:\n",
        "# 1. Get predictions from your existing Text+Struct model (Model 1)\n",
        "#    (Assuming lgb_model and X_train/test_final are available from the previous success)\n",
        "preds_train_text_log = lgb_model.predict(X_train_final)\n",
        "preds_test_text_log = lgb_model.predict(X_test_final)\n",
        "\n",
        "# 2. Prepare Blending Data\n",
        "X_blend_train = np.column_stack([preds_train_text_log, preds_train_img_log])\n",
        "X_blend_test = np.column_stack([preds_test_text_log, preds_test_img_log])\n",
        "\n",
        "# 3. Train the Blending Model (Simple and fast Ridge Regression)\n",
        "blender = Ridge(alpha=1.0) # A small regularization\n",
        "blender.fit(X_blend_train, y_train)\n",
        "\n",
        "# 4. Generate Final Log Predictions\n",
        "final_preds_test_log = blender.predict(X_blend_test)\n",
        "\n",
        "# --- 5. Final Submission ---\n",
        "\n",
        "# Inverse transform and clamp\n",
        "final_preds_price = np.maximum(0.01, np.expm1(final_preds_test_log))\n",
        "\n",
        "# Format and Save (Ensuring 75,000 rows and correct header/index handling)\n",
        "output_df_ensemble = pd.DataFrame({\n",
        "    'sample_id': df_test_raw['sample_id'],\n",
        "    'price': final_preds_price\n",
        "})\n",
        "\n",
        "OUTPUT_FILE = 'submission_multimodal_ensemble.csv'\n",
        "output_df_ensemble.to_csv(\n",
        "    OUTPUT_FILE,\n",
        "    index=False,\n",
        "    header=True,\n",
        "    float_format='%.2f'\n",
        ")\n",
        "\n",
        "print(f\"\\n✅ Multimodal Ensemble Submission file created: {OUTPUT_FILE}\")\n",
        "print(\"This blended model is optimized for high accuracy and speed.\")"
      ],
      "metadata": {
        "id": "-lRonqA7asdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#first submission was done using this\n",
        "'''\n",
        "# --- Final Submission Code (Stage 4) ---\n",
        "\n",
        "# Get sample_ids from the test set\n",
        "sample_ids = df_test_raw['sample_id']\n",
        "\n",
        "output_df = pd.DataFrame({\n",
        "    'sample_id': sample_ids,\n",
        "    'price': y_pred_price\n",
        "})\n",
        "\n",
        "# Save to CSV (CRITICAL: Ensure HEADER is included by default, or explicitly set to True)\n",
        "OUTPUT_FILE = 'submission_final_with_header.csv'\n",
        "output_df.to_csv(\n",
        "    OUTPUT_FILE,\n",
        "    index=False,\n",
        "    header=True,             # <-- Ensure header is explicitly set to True\n",
        "    float_format='%.2f'\n",
        ")\n",
        "\n",
        "print(f\"\\n✅ Submission file created: {OUTPUT_FILE}\")'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dM7lbsgFKr6Q",
        "outputId": "3809d3fd-825d-4b59-b9bc-c26f66a39e5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Submission file created: submission_final_with_header.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oMMmPGGMYU4A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}